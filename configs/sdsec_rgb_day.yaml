DEVICE          : cuda              # device used for training and evaluation (cpu, cuda, cuda0, cuda1, ...)
SAVE_DIR        : 'output_viz_sdsec'          # output folder name used for saving the model, logs and inference results

MODEL:
  NAME          : CMNeXt                                            # name of the model you are using
  BACKBONE      : CMNeXt-B2                                         # model variant
  BACKBONE_FLAG : False
  PRETRAINED_BACKBONE    : 'checkpoints/pretrained/segformer/mit_b2.pth'     # backbone model's weight 
  # PRETRAINED        : '/home/xiaoshan/work/adap_v/DELIVER/output/DSEC_CMNeXt-B2_i/model_day_11_CMNeXt_CMNeXt-B2_DSEC_epoch356_73.55.pth'     # backbone model's weight 
  # PRETRAINED    : 'output/DSEC_CMNeXt-B2_i/model_day_11_CMNeXt_CMNeXt-B2_DSEC_epoch220_73.99.pth'
  PRETRAINED      : 'paper_results/model_day_11_CMNeXt_CMNeXt-B2_DSEC_epoch20_65.4.pth'
  FLOW_NET_FLAG : True
  FLOW_NET      : 'eraft'
  # RESUME_FLOWNET: 'model_day_11_CMNeXt_CMNeXt-B2_DSEC_epoch106_0.41733222244595924.pth'
  RESUME_FLOWNET: 'checkpoints/pretrained/flownet/dsec.tar'
  # FLOW_NET      : 'bflow'
  # RESUME_FLOWNET: 'E_LU4_BD2.ckpt'
  # RESUME_FLOWNET: 'flow_network.pth'
  RESUME        : ''                                                # checkpoint file 
  # RESUME_FLOWNET: ''

DATASET:
  NAME          : DSEC                                          # dataset name to be trained with (camvid, cityscapes, ade20k)
  TYPE          : sdsec
  # ROOT          : '/mnt/sdc/lxy/datasets/DSEC/DSEC/dsec_anytime/day'                                   # dataset root path
  ROOT          : "/mnt/sdb/datasets/synthesis_N11_45_${DURATION}"                                   # dataset root path
  # ROOT          : '/mnt/sdc/lxy/datasets/DSEC/DSEC/dsec_anytime_100/synthesis_N11_45'                                   # dataset root path
  # ROOT          : '/mnt/sdc/lxy/datasets/DSEC/DSEC/dsec_anytime_100/day+synthesis_L'                                   # dataset root path
  IGNORE_LABEL  : 255
  MODALS        : ['img']
  # MODALS        : ['img', 'depth']
  # MODALS        : ['img', 'event']
  # MODALS        : ['img', 'lidar']
  # MODALS        : ['img', 'depth', 'event']
  # MODALS        : ['img', 'depth', 'lidar']
  # MODALS        : ['img', 'depthd', 'event', 'lidar']

TRAIN:
  IMAGE_SIZE    : [440, 640]    # training image size in (h, w)
  BATCH_SIZE    : 4               # batch size used to train
  EPOCHS        : 400             # number of epochs to train
  EVAL_START    : 0             # evaluation interval start
  EVAL_INTERVAL : 1               # evaluation interval during training
  AMP           : false           # use AMP in training
  DDP           : true            # use DDP training

LOSS:
  NAME          : OhemCrossEntropy          # loss function name 
  CLS_WEIGHTS   : false            # use class weights in loss calculation

OPTIMIZER:
  NAME          : adamw           # optimizer name
  LR            : 0.0001         # initial learning rate used in optimizer
  WEIGHT_DECAY  : 0.005            # decay rate used in optimizer

SCHEDULER:
  NAME          : warmuppolylr    # scheduler name
  POWER         : 0.95             # scheduler power
  WARMUP        : 10              # warmup epochs used in scheduler
  WARMUP_RATIO  : 0.1             # warmup ratio
  

EVAL:
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgb.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgbd.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_deliver_rgbe.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgb.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgbl.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgbde.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgbdl.pth'
  # MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgbdel.pth'
  IMAGE_SIZE    : [440, 640]                            # evaluation image size in (h, w)        
  BATCH_SIZE    : 1                                       # batch size used to train               
  MSF: 
    ENABLE      : false                                   # multi-scale and flip evaluation  
    FLIP        : true                                    # use flip in evaluation  
    SCALES      : [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]       # scales used in MSF evaluation                


TEST:
  MODEL_PATH    : 'output/DSEC/cmnext_b2_kitti360_rgbe.pth'    # trained model file path
  FILE          : 'data/DSEC'                          # filename or foldername 
  IMAGE_SIZE    : [440, 640]                            # inference image size in (h, w)
  OVERLAY       : false                                   # save the overlay result (image_alpha+label_alpha)